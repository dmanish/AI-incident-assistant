# Copy this file to `.env` for local runs (DON'T commit `.env`)
# This file is used by both Codespaces and Docker

# LLM API Keys (system will try in order: OpenAI -> Anthropic -> Google)
# At least one is required for agent functionality
OPENAI_API_KEY=your_openai_key_here
ANTHROPIC_API_KEY=your_anthropic_key_here
GOOGLE_API_KEY=your_google_key_here

# LLM Model Configuration (optional - defaults shown)
OPENAI_MODEL=gpt-4o-mini
OPENAI_ROUTER_MODEL=gpt-4o-mini
ANTHROPIC_MODEL=claude-3-haiku-20240307
GOOGLE_MODEL=gemini-1.5-flash

# JWT secret for authentication tokens
JWT_SECRET=replace_with_random_32char_string

# Which embedding backend to use: openai or local
#   local  → all-MiniLM-L6-v2 (CPU)
#   openai → text-embedding-3-small
EMBED_BACKEND=local

# Backend settings
PORT=8080
HOST=0.0.0.0

# Data directories
# For Codespaces/local: Use relative paths or leave commented (auto-detected)
# For Docker: Uncomment and use /app paths
# CHROMA_DB_DIR=/app/data/chroma
# DUCK_DB_PATH=/app/data/logs/security.duckdb
# AUDIT_DIR=/app/data/logs

# Frontend (React) environment variable
# For Docker: set in docker-compose.yml as VITE_BACKEND_URL=http://api:8080
# For Codespaces: set in start-codespaces.sh as VITE_BACKEND_URL=http://localhost:8080
VITE_BACKEND_URL=http://localhost:8080
